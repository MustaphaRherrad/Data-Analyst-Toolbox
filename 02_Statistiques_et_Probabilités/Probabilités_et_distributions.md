# ProbabilitÃ©s_et_distributions.md

Je vous prÃ©sente un petit **tutoriel clair et structurÃ©** sur les **probabilitÃ©s et distributions**, des concepts fondamentaux en **statistiques et Data Science**. 

---

## ğŸ“Š **1. Notions de base en probabilitÃ©s**  
Les probabilitÃ©s permettent de **quantifier lâ€™incertitude** et dâ€™Ã©valuer la **chance** quâ€™un Ã©vÃ©nement se produise.

### **ğŸ”¹ ExpÃ©riences alÃ©atoires**  
Une **expÃ©rience alÃ©atoire** est une expÃ©rience dont le rÃ©sultat **nâ€™est pas prÃ©visible avec certitude**. 
Exemple :  
- **Lancer un dÃ©** â†’ On ne sait pas quel chiffre va sortir de 1 Ã  6.  
- **Tirer une carte dans un jeu** â†’ Chaque carte a une certaine probabilitÃ© dâ€™Ãªtre tirÃ©e.  

### **ğŸ”¹ Notions fondamentales**  
- **Ã‰vÃ©nement** : RÃ©sultat possible dâ€™une expÃ©rience (ex. : obtenir un "6" sur un dÃ©).  
- **Espace des Ã©vÃ©nements** (`Î©`) : Ensemble de **tous les rÃ©sultats possibles** (ex. : {1,2,3,4,5,6} pour un dÃ©).  
- **ProbabilitÃ© dâ€™un Ã©vÃ©nement** (`P(E)`) : Nombre entre **0** et **1** indiquant la chance quâ€™un Ã©vÃ©nement se rÃ©alise.  
  - **0** â†’ Impossible  
  - **1** â†’ Certain  
  - **Entre 0 et 1** â†’ Possible avec une probabilitÃ© donnÃ©e  

ğŸ’¡ **Formule de base** :  
Si tous les Ã©vÃ©nements sont **Ã©quiprobables** c'est-Ã -dire qu'ils tous la mÃªme chance de soritr, alors la probabilitÃ© dâ€™un Ã©vÃ©nement `E` est :  
\[
P(E) = \frac{\text{Nombre de cas favorables}}{\text{Nombre de cas possibles}}
\]

---

## ğŸ“‰ **2. Distributions de probabilitÃ©**  
Les **distributions de probabilitÃ©** dÃ©crivent **comment** les valeurs dâ€™une variable alÃ©atoire sont rÃ©parties.

### **ğŸ”¹ Types de variables alÃ©atoires**  
- **Variable alÃ©atoire discrÃ¨te** â†’ Prend un **nombre limitÃ©** de valeurs (ex. : lancer de dÃ©).  
- **Variable alÃ©atoire continue** â†’ Prend une **infinitÃ©** de valeurs (ex. : la tempÃ©rature).  

---

### **ğŸ“Œ 3. Principales distributions de probabilitÃ©**  

#### **ğŸ”¹ Loi Uniforme**  
Chaque valeur a la **mÃªme probabilitÃ©** dâ€™Ãªtre choisie.  
Exemple : Un **dÃ© Ã©quilibrÃ©** â†’ Chaque face a `1/6` de chances dâ€™apparaÃ®tre.  

#### **ğŸ”¹ Loi de Bernoulli**  
ModÃ©lise un Ã©vÃ©nement avec **deux rÃ©sultats possibles** (`succÃ¨s` ou `Ã©chec`).  
Exemple : **Pile ou face** â†’ `P(Pile) = 0.5`, `P(Face) = 0.5`.

#### **ğŸ”¹ Loi Binomiale**  
ModÃ©lise le nombre de **succÃ¨s** dans une sÃ©rie dâ€™expÃ©riences indÃ©pendantes.  
Exemple : **Nombre de "6" obtenus en lanÃ§ant 10 dÃ©s**.

\[
P(k) = C(n, k) p^k (1 - p)^{n - k}
\]
oÃ¹ :
- `C(n, k)` â†’ Nombre de faÃ§ons de choisir `k` succÃ¨s parmi `n` essais.  
- `p` â†’ ProbabilitÃ© de succÃ¨s.  
- `k` â†’ Nombre de succÃ¨s recherchÃ©s.  

#### **ğŸ”¹ Loi Normale (Gaussienne)**  
La plus importante ! ModÃ©lise les phÃ©nomÃ¨nes **naturels** et **sociaux**. Elle suit une **courbe en cloche** dÃ©finie par :  

\[
f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x - \mu)^2}{2\sigma^2}}
\]

oÃ¹ :
- `Î¼` â†’ Moyenne  
- `Ïƒ` â†’ Ã‰cart-type  

Elle est omniprÃ©sente en **science des donnÃ©es** et en **modÃ©lisation statistique**.

---

### **ğŸ“Œ 4. Illustration en Python**  
On peux **visualiser ces distributions** avec **Pandas & Matplotlib** !  

```python
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats

# GÃ©nÃ©ration de donnÃ©es normales
data = np.random.normal(loc=0, scale=1, size=1000)

# Tracer lâ€™histogramme
plt.hist(data, bins=30, density=True, alpha=0.6, color='b')

# Tracer la fonction de densitÃ© normale
xmin, xmax = plt.xlim()
x = np.linspace(xmin, xmax, 100)
p = stats.norm.pdf(x, 0, 1)
plt.plot(x, p, 'k', linewidth=2)

plt.title("Distribution Normale")
plt.show()
```

---

## **ğŸ¯ Conclusion**
Les **probabilitÃ©s et distributions** sont **essentielles** en Data Science et en analyse statistique !  

âœ”ï¸ **ProbabilitÃ©s** â†’ Quantifient lâ€™incertitude.  
âœ”ï¸ **Distributions** â†’ ModÃ©lisent la rÃ©partition des valeurs.  
âœ”ï¸ **Loi Normale** â†’ Pilier des statistiques.  


